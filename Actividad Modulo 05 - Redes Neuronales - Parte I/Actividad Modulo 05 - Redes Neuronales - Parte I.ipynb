{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6b98d7",
   "metadata": {},
   "source": [
    "## Redes Neuronales - Parte I\n",
    "\n",
    "En esta actividad vamos a aprender a desarrollar nuestra propia red neuronal para reconocimiento de imagenes.\n",
    "\n",
    "Para ello, vamos a trabajar con un dataset (digits.csv) que contiene imagenes en escala de grises de 28x28 pixeles (un total de 784 pixeles). Cada imagen representa un digito (desde el 0 al 9) escrito a mano. Cada pixel tiene un valor asociado entre 0 y 255 que indica la luminosidad u oscuridad de dicho pixel (valores mas grandes indican mayor oscuridad).\n",
    "\n",
    "El dataset tiene 785 columnas, en donde la primera columna es el label del dataset y las columnas restantes son los features que indican los valores de cada pixel de la imagen.\n",
    "\n",
    "La idea es utilizar este dataset para reconocer digitos que fueron escritos manualmente utilizando una red neuronal simple. En este caso, vamos a reconocer unicamente aquellas imagenes que representen el número 2. Es decir, la idea es hacer una clasificación binaria en donde, dada una imagen de un digito escrito manualmente, se determine si corresponde con el numero 2 o no.\n",
    "\n",
    "En primer lugar, carguemos en memoria (en un pandas DataFrame) el dataset, analicemos los labels y observemos algunas imagenes.\n",
    "\n",
    "\n",
    "#### Ejercicio 1\n",
    "a) Escribir en Python un programa para dividir el dataset del archivo digits.csv almacenando los features en una variable llamada **X**  y los labels en una variable llamada **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c828b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = pd.read_csv('digits.csv')\n",
    "digits.head()\n",
    "\n",
    "# Almacenar features en una variable llamada X y labels en una variable llamada y.\n",
    "# Selecciona todas las filas (:) y todas las columnas a partir de la segunda columna en adelante (1:).\n",
    "X = digits.iloc[:,1:]\n",
    "\n",
    "# Selecciona todas las filas (:) y solo la primera columna (0).\n",
    "y = digits.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cf506",
   "metadata": {},
   "source": [
    "b) Observar la cantidad de ejemplos por cada label, analizando la variable **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde0f631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir la cantidad de ejemplos por cada clase (ordenados)\n",
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83a0c0",
   "metadata": {},
   "source": [
    "## Visualización de imagenes del dataset\n",
    "Las imagenes (28px x 28px) fueron cargadas en memoria en un pandas Dataframe que representa un vector de 1 unica dimension (1D) con 784 valores, cada una representada por un pandas Series. Para imprimir y visualizar, como asi tambien para crear una red neuronal que las lea debemos reformatear esta estructura y convertirla en una matriz (array) de 3 dimensiones (3D) de 28x28x1. Para ello utilizamos el metodo .reshape():\n",
    "\n",
    "```\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "```\n",
    "\n",
    "**Aclaración:** el primer parametro de reshape, que se encuentra en -1, toma por defecto la dimension del array (formado por X.values que contiene todos los valores del DataFrame en un array de 2 dimensiones). Ver [documentación](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy-reshape) para más info. \n",
    "\n",
    "Tensorflow y Keras requieren una dimensión extra al final que se corresponde con los canales de colores. En este caso, las imagenes del dataset son en la escala de grises con los cual utilizaremos un unico canal (para imagenes RGB existen 3 canales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391e9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27965e",
   "metadata": {},
   "source": [
    "A continuación observemos dos imagenes distintas y sus labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e336297e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1= plt.imshow(X[10][:,:,0])\n",
    "display(\"LABEL:\", y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9db9860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[16][:,:,0])\n",
    "display(\"LABEL:\", y[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9829f5",
   "metadata": {},
   "source": [
    "### Redefinición de los Labels\n",
    "Como lo que queremos hacer es un clasificador binario que unicamente detecte imagenes con el valor 2, tenemos que modificar los labels para tener unicamente dos valores y=1, cuando la imagen representa un 2 e y=0, cuando la imagen representa cualquier otro digito.\n",
    "\n",
    "Para ello hacemos uso del potencial de pandas, que nos permite modificar valores de columnas facilmente utilizando condiciones y filtros. Por ejemplo, si quisieramos cambiar el valor de todos los labels que se corresponden con el digito 9 por un valor igual a -1, podemos hacer:\n",
    "\n",
    "```\n",
    "y.loc[y==9] = -1\n",
    "```\n",
    "\n",
    "Esta linea de codigo buscaria en la variable **y** (que es una pandas Series) todas aquellas filas que contienen el valor 9 y los reemplazaria con un valor igual a -1.\n",
    "\n",
    "De esta misma forma, podremos modificar nuestro dataset para que contenga dos valores y=1, para todos los labels igual a 2 e y=0 para todos los labels distintos de 2.\n",
    "\n",
    "#### Ejercicio 2\n",
    "a) Modificar los valores de **y** para que solo contenga los labels y=1 e y=0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fcc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar y tal que si la imágen que representa es un 2, su label sea 1,\n",
    "# y si la imágen que representa no es un 2, su label sea 0\n",
    "y.loc[y!=2] = 0\n",
    "y.loc[y==2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83657fd",
   "metadata": {},
   "source": [
    "b) Observar la cantidad de ejemplos por cada label, analizando la variable **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a482315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    37823\n",
       "1     4177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535aa7e0",
   "metadata": {},
   "source": [
    "Como vimos anteriormente, para los algoritmos de ML en general suele ser mejor normalizar los datos para que el proceso de aprendizaje sea más efectivo y eficiente.\n",
    "\n",
    "Para ello normalizamos dividiendo por 255 todos los valores de pixeles que se encuentran en la variable X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4374b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb164b8c",
   "metadata": {},
   "source": [
    "En este punto tenemos unicamente dos labels: \n",
    "- **0**, para aquellas imagenes que no representan el digito 2\n",
    "- **1**, para las imagenes que representan el digito 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5f54b",
   "metadata": {},
   "source": [
    "### Creación del modelo con Tensorflow y Keras\n",
    "\n",
    "A continuación vamos a definir el modelo del clasificador binario. Para ello, veamos como es posible crear redes neuronales utilizando el framework Tensorflow.\n",
    "\n",
    "Lo primero que tenemos que hacer es importar el modulo de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a42760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Imprimimos la version de tensorflow\n",
    "display(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc329dc",
   "metadata": {},
   "source": [
    "En particular vamos a utilizar Keras (tf.keras), que es la API de alto nivel de TensorFlow para construir y entrenar modelos de aprendizaje profundo. \n",
    "\n",
    "Keras provee de una serie de clases que nos permiten construir facilmente redes neuronales en una pocas lineas de codigo. Veamos algunas de ellas:\n",
    "\n",
    "[Sequential](https://keras.io/api/models/sequential/): Esta clase define una secuencia de layers en la red neuronal. Suele utilizarse como contenedor de toda la red y sus layers internas.\n",
    "\n",
    "[Flatten](https://keras.io/api/layers/reshaping_layers/flatten/): En general las imágenes estan representadas por una matriz de píxeles (en este ejemplo, de 28x28). La clase Flatten simplemente toma esa matriz y la convierte en una matriz unidimensional (1D).\n",
    "\n",
    "[Dense](https://keras.io/api/layers/core_layers/dense/): La clase Dense define la layer más simple de redes neuronales en donde todas las neuronas se conectan con todas las entradas y todas las salidas.\n",
    "\n",
    "Recordemos que cada layer de neuronas necesita una [función de activación](https://keras.io/api/layers/activations/) para decirles qué hacer. Hay muchas opciones, pero por ahora solo usaremos la funcion sigmoidea ('sigmoid').\n",
    " \n",
    "Teniendo este conocimiento basico de Keras, la construcción del modelo se define de la siguiente manera:\n",
    "\n",
    "\n",
    " \n",
    "```\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layer_1)\n",
    "...\n",
    "model.add(layer_n)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "En general, si se trata de imagenes, la primera layer del modelo es de la clase Flatten. Las siguientes layers suelen ser del tipo Dense, con diferentes cantidades de neuronas. \n",
    "\n",
    "Recordemos que, como en nuestro caso estamos realizando un clasificador binario, necesitamos que la ultima layer tenga una única neurona.\n",
    "\n",
    "Ahora que sabemos como construir una red neuronal simple con Keras, vamos a definir un modelo para nuestro problema.\n",
    "\n",
    "\n",
    "#### Ejercicio 3\n",
    "a) Crear un modelo de red neuronal con Keras, usando la clase Sequential. Luego, agregarle 3 layers distintas: una layer para convertir las imagenes en una matriz 1D, una layer densa con 128 neuronas y una layer de salida tambien densa con una única neurona.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218da835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo de red neuronal con Keras, usando la clase Sequential.\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Agregamos 3 layers distintas: \n",
    "# Una para convertir las imágenes en una matriz 1D\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# Una layer densa con 128 neuronas \n",
    "model.add(tf.keras.layers.Dense(128, activation='sigmoid'))\n",
    "# Una layer de salida densa con una única neurona.\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb62be",
   "metadata": {},
   "source": [
    "b) Compile el modelo utilizando el metodo [.compile()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile). La función de costo que vamos a utilizar es 'binary_crossentropy' y como metrica solo 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a82f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97336402",
   "metadata": {},
   "source": [
    "**c)** Entrene el modelo utilizando el método [.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), con los valores de **X** y de **y**. Setee la cantidad de epochs a 5. \n",
    "\n",
    "**Aclaración:** La cantidad de epochs se refiere al paso completo de datos de los entrenamiento a través del modelo. En este ejemplo con 5 pasadas es suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42fafb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1313/1313 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9748\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0629 - accuracy: 0.9820\n",
      "Epoch 3/5\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0482 - accuracy: 0.9863\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0389 - accuracy: 0.9889\n",
      "Epoch 5/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0338 - accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2437fcb4fa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d467c",
   "metadata": {},
   "source": [
    "**d)** Generar predicciones para el dataset completo (**X**), utilizando el metodo [.predict()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict).\n",
    "\n",
    "**Aclaración:** Recordemos que  el metodo .predict() devuelve la probabilidad de que pertenezca a la clase positiva. En este ejemplo, sera la probabilidad de que la imagen sea efectivamente un 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7caa0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c44f9",
   "metadata": {},
   "source": [
    "**e)** Imprimir las predicciones generadas por el modelo para las imagenes visualizadas anteriormente (indices 10 y 16). Recordemos que la imagen del indice 10 corresponde al digito 8 y la imagen del indice 16 corresponde al digito 2. En este caso, imprimir el label real y el label estimado por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ad91bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la imágen del índice 10 tenemos la predicción [1.1642242e-05]. Su valor real es 0.\n",
      "Para la imágen del índice 16 tenemos la predicción [0.9664814]. Su valor real es 1.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Para la imágen del índice 10 tenemos la predicción {predictions[10]}. Su valor real es {y[10]}.\")\n",
    "print(f\"Para la imágen del índice 16 tenemos la predicción {predictions[16]}. Su valor real es {y[16]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53c72f",
   "metadata": {},
   "source": [
    "Finalmente realizamos una evaluación del modelo en el dataset de entrenamiento. \n",
    "\n",
    "Tengamos en cuenta que en este ejemplo no dividimos el dataset en dataset de entrenamiento y dataset de testeo porque el objetivo era aprender a construir redes neuronales simples. Es por ello que el accuracy que arroje el metodo [.evaluate()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) nos va a decir que tan preciso es el modelo en predecir los labels de los mismos ejemplos con los que fue entrenado. **Para evaluar con mayor precision el rendimiento del modelo deberiamos evaluarlo con un dataset desconocido por el.**\n",
    "\n",
    "\n",
    "Observar que el metodo .evaluate devuelve un vector con dos valores: el error y el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad944c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0304 - accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03037452884018421, 0.9915476441383362]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
